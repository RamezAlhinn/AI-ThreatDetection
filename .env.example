# LLM API Configuration
# Get your free API key from: https://huggingface.co/settings/tokens
HF_API_KEY=hf_your_api_key_here

# Hugging Face model endpoint (free inference API)
HF_API_URL=https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2

# Mode Selection
# Set to 'true' for deterministic mock responses (no API calls, perfect for demos)
# Set to 'false' to use real LLM API (requires valid HF_API_KEY)
USE_MOCK_MODEL=true

# Storage Configuration
STORAGE_PATH=data/predictions.csv

# LLM Request Timeout (seconds)
LLM_TIMEOUT=30
