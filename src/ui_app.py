"""
Streamlit UI for AI Threat Detection Agent - Simplified & Visual
"""

import streamlit as st
import pandas as pd
from typing import List, Dict, Any
import os
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import settings, validate_config, is_mock_mode
from threat_agent import ThreatDetectionAgent
from storage import create_store
from metrics import QualityMetrics, evaluate_predictions

# Page configuration
st.set_page_config(
    page_title="AI Threat Detection Agent",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

def load_sample_logs() -> List[str]:
    """Load sample logs from file."""
    sample_path = "data/sample_logs.txt"
    if not os.path.exists(sample_path):
        return ["2024-01-15 10:23:41 INFO user=alice action=login ip=192.168.1.100 status=success"]
    with open(sample_path, 'r') as f:
        logs = [line.strip() for line in f if line.strip()]
    return logs

def render_overview_tab():
    """Simplified overview with key visuals."""
    
    # Hero section
    col1, col2 = st.columns([2, 1])
    with col1:
        st.title("ğŸ›¡ï¸ AI Threat Detection Agent")
        st.markdown("### LLM-Powered Cybersecurity PoC")
    with col2:
        mode = "ğŸ­ Mock Mode" if is_mock_mode() else "ğŸŒ Live API"
        st.metric("Status", mode, "Active")
    
    st.divider()
    
    # Core capabilities - visual cards
    st.subheader("ğŸ¯ Core Capabilities")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        #### ğŸ” AI Framework Evaluation
        - Compare LLM APIs vs self-hosted
        - Mock mode for reliability
        - Easy to swap backends
        """)
    
    with col2:
        st.markdown("""
        #### ğŸ¤– PoC AI Agent
        - Real-time threat detection
        - Natural language explanations
        - Actionable recommendations
        """)
    
    with col3:
        st.markdown("""
        #### ğŸ“Š Quality Monitoring
        - Accuracy metrics
        - Confusion matrix
        - Human-in-the-loop workflow
        """)
    
    st.divider()
    
    # Simple architecture diagram
    st.subheader("ğŸ—ï¸ Architecture")
    
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        st.markdown("""
        **ğŸ“¥ INPUT**
        - Security logs
        - User events
        - System alerts
        """)
    
    with col2:
        st.markdown("""
        **âš™ï¸ PROCESSING**
        - LLM Analysis
        - Pattern Matching
        - Risk Scoring
        """)
    
    with col3:
        st.markdown("""
        **ğŸ“¤ OUTPUT**
        - Threat Level
        - Explanation
        - Recommended Action
        """)
    
    # Flow diagram
    st.markdown("""
    ```
    Log Entry  â†’  Threat Agent  â†’  LLM Client  â†’  Classification
                                       â†“
                                  Mock/Real API
    ```
    """)
    
    st.divider()
    
    # Key features
    st.subheader("âœ¨ Why This Design?")
    
    features = {
        "ğŸ­ Mock Mode": "Demo-ready without network/API",
        "ğŸª¶ Lightweight": "No PyTorch/TensorFlow needed",
        "ğŸ”§ Modular": "Swap components easily",
        "ğŸ“ˆ Quality-First": "Built-in monitoring"
    }
    
    cols = st.columns(4)
    for idx, (feature, desc) in enumerate(features.items()):
        with cols[idx]:
            st.metric(feature, desc)

def render_demo_tab():
    """Clean, focused demo interface."""
    st.header("ğŸš€ Live Threat Detection")
    
    # Initialize agent
    agent = ThreatDetectionAgent()
    sample_logs = load_sample_logs()
    
    # Simple input selection
    st.markdown("### Select Logs to Analyze")
    
    input_method = st.radio(
        "Input method:",
        ["ğŸ“‹ Example Logs", "âœï¸ Custom Logs"],
        horizontal=True,
        label_visibility="collapsed"
    )
    
    if input_method == "ğŸ“‹ Example Logs":
        selected_indices = st.multiselect(
            "Choose logs:",
            range(len(sample_logs)),
            format_func=lambda i: f"Log {i+1}: {sample_logs[i][:70]}...",
            default=[0, 4, 7]
        )
        logs_to_analyze = [sample_logs[i] for i in selected_indices]
    else:
        custom_logs = st.text_area(
            "Paste logs (one per line):",
            height=150,
            placeholder="2024-01-15 10:23:41 INFO user=alice action=login ip=192.168.1.100 status=success"
        )
        logs_to_analyze = [line.strip() for line in custom_logs.split('\n') if line.strip()]
    
    # Analyze button
    if st.button("ğŸ” Analyze Logs", type="primary", disabled=len(logs_to_analyze) == 0, use_container_width=True):
        with st.spinner("ğŸ¤– AI analyzing..."):
            results = agent.analyze_logs_batch(logs_to_analyze)
            st.session_state['demo_results'] = results
    
    # Display results
    if 'demo_results' in st.session_state and st.session_state['demo_results']:
        results = st.session_state['demo_results']
        
        st.divider()
        st.markdown("### ğŸ“Š Results")
        
        # Summary metrics
        summary = agent.get_summary_stats(results)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("âœ… Benign", summary['benign_count'], f"{summary['benign_pct']:.0f}%")
        with col2:
            st.metric("âš ï¸ Suspicious", summary['suspicious_count'], f"{summary['suspicious_pct']:.0f}%")
        with col3:
            st.metric("ğŸš¨ Malicious", summary['malicious_count'], f"{summary['malicious_pct']:.0f}%")
        with col4:
            st.metric("ğŸ¯ Confidence", f"{summary['avg_confidence']:.0%}")
        
        # Results table with color coding
        st.markdown("### ğŸ“‹ Detailed Analysis")
        
        for idx, result in enumerate(results):
            prediction = result['prediction']
            
            # Color based on threat level
            if prediction == 'malicious':
                color = "ğŸš¨"
                bg_color = "#ffebee"
            elif prediction == 'suspicious':
                color = "âš ï¸"
                bg_color = "#fff9e6"
            else:
                color = "âœ…"
                bg_color = "#e8f5e9"
            
            with st.container():
                st.markdown(f"""
                <div style="background-color: {bg_color}; padding: 15px; border-radius: 5px; margin-bottom: 10px;">
                    <h4>{color} {prediction.upper()} (Confidence: {result['confidence']:.0%})</h4>
                    <p><strong>Log:</strong> {result['log']}</p>
                    <p><strong>Reason:</strong> {result['explanation']}</p>
                    <p><strong>Action:</strong> {result['recommended_action']}</p>
                </div>
                """, unsafe_allow_html=True)
        
        # Save option
        st.divider()
        if st.button("ğŸ’¾ Save Results", use_container_width=True):
            store = create_store()
            ids = store.save_predictions_batch(results)
            st.success(f"âœ… Saved {len(ids)} predictions")

def render_quality_tab():
    """Simplified quality monitoring."""
    st.header("ğŸ“ˆ Quality Monitoring")
    
    st.markdown("### Evaluate AI performance against labeled data")
    
    try:
        store = create_store()
        labeled_df = store.load_labeled_data()
        
        st.info(f"ğŸ“ {len(labeled_df)} labeled examples loaded")
        
        if st.button("ğŸ”„ Run Evaluation", type="primary", use_container_width=True):
            with st.spinner("ğŸ¤– Evaluating..."):
                agent = ThreatDetectionAgent()
                
                predictions = []
                for _, row in labeled_df.iterrows():
                    result = agent.analyze_log(row['log'])
                    predictions.append(result)
                
                labeled_df['prediction'] = [p['prediction'] for p in predictions]
                labeled_df['confidence'] = [p['confidence'] for p in predictions]
                labeled_df['explanation'] = [p['explanation'] for p in predictions]
                
                st.session_state['evaluation_df'] = labeled_df
        
        if 'evaluation_df' in st.session_state:
            eval_df = st.session_state['evaluation_df']
            metrics = QualityMetrics()
            summary, mistakes = evaluate_predictions(eval_df)
            
            st.divider()
            
            # Big metrics
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ¯ Accuracy", f"{summary['overall_accuracy']:.0%}", help="Overall correct predictions")
            with col2:
                st.metric("ğŸ“Š Total Samples", summary['total_samples'])
            with col3:
                errors = len(mistakes['all_errors'])
                st.metric("âŒ Errors", errors, f"-{(errors/summary['total_samples']*100):.0f}%")
            
            st.divider()
            
            # Per-class metrics
            st.markdown("### ğŸ“Š Performance by Class")
            
            per_class_data = []
            for cls, metrics_dict in summary['per_class_metrics'].items():
                per_class_data.append({
                    'Threat Type': cls.capitalize(),
                    'Precision': f"{metrics_dict['precision']:.0%}",
                    'Recall': f"{metrics_dict['recall']:.0%}",
                    'F1-Score': f"{metrics_dict['f1']:.0%}",
                    'Count': metrics_dict['support']
                })
            
            st.dataframe(pd.DataFrame(per_class_data), use_container_width=True, hide_index=True)
            
            # Confusion matrix
            st.markdown("### ğŸ”€ Confusion Matrix")
            st.caption("Rows = Actual | Columns = Predicted")
            
            confusion = summary['confusion_matrix']
            confusion_df = pd.DataFrame(confusion).T
            st.dataframe(confusion_df, use_container_width=True)
            
            # Key mistakes
            st.divider()
            st.markdown("### ğŸ” Critical Mistakes")
            
            col1, col2 = st.columns(2)
            
            with col1:
                fn_df = mistakes['false_negatives_malicious']
                st.markdown("#### ğŸš¨ Missed Threats")
                if len(fn_df) > 0:
                    st.error(f"{len(fn_df)} malicious events missed!")
                    st.dataframe(fn_df[['log', 'true_label', 'prediction']], use_container_width=True, hide_index=True)
                else:
                    st.success("âœ… No missed threats")
            
            with col2:
                fp_df = mistakes['false_positives_malicious']
                st.markdown("#### âš ï¸ False Alarms")
                if len(fp_df) > 0:
                    st.warning(f"{len(fp_df)} false alarms")
                    st.dataframe(fp_df[['log', 'true_label', 'prediction']], use_container_width=True, hide_index=True)
                else:
                    st.success("âœ… No false alarms")
    
    except FileNotFoundError:
        st.error("âŒ Labeled data not found at `data/labeled_logs.csv`")

def render_framework_tab():
    """Simplified framework comparison."""
    st.header("ğŸ”§ Framework Evaluation")
    
    st.markdown("### Comparing AI Approaches for Security")
    
    # Comparison table
    comparison_data = {
        "Approach": [
            "ğŸ†“ Free LLM API",
            "ğŸ  Self-Hosted LLM",
            "ğŸ’° Commercial API",
            "ğŸ“ Rule-Based",
            "ğŸŒ² Classical ML"
        ],
        "Speed": ["Medium", "Fast", "Medium", "Very Fast", "Fast"],
        "Privacy": ["âš ï¸ External", "âœ… Full", "âš ï¸ External", "âœ… Local", "âœ… Local"],
        "Cost": ["âœ… Free", "ğŸ’° High", "ğŸ’° Per-use", "âœ… Low", "âœ… Low"],
        "Flexibility": ["High", "Very High", "High", "Low", "Medium"],
        "Explanations": ["âœ… Yes", "âœ… Yes", "âœ… Yes", "âŒ No", "âŒ No"],
        "PoC Ready": ["âœ… Yes", "âš ï¸ Setup", "âœ… Yes", "âœ… Yes", "âœ… Yes"]
    }
    
    st.dataframe(pd.DataFrame(comparison_data), use_container_width=True, hide_index=True)
    
    st.divider()
    
    # Why our choice
    st.markdown("### ğŸ¯ Our Choice: Free LLM API + Mock Mode")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **âœ… Advantages**
        - No infrastructure needed
        - Free tier available
        - Natural language explanations
        - Mock mode = reliable demos
        - Fast to iterate
        """)
    
    with col2:
        st.markdown("""
        **âš ï¸ Trade-offs**
        - Network latency
        - Rate limits
        - Data privacy concerns
        - API dependency
        
        *Mitigated by mock mode!*
        """)

def render_future_tab():
    """Simplified future work."""
    st.header("ğŸ”® Future Extensions")
    
    # Extension cards
    extensions = {
        "ğŸ¤– Multi-Agent System": [
            "Phishing email classifier",
            "SIEM alert triage",
            "Incident report drafter",
            "Vulnerability explainer"
        ],
        "ğŸ‘¥ Human-in-the-Loop": [
            "Analyst feedback buttons",
            "Approval workflows",
            "Active learning",
            "Collaborative triage"
        ],
        "ğŸ“Š Advanced Monitoring": [
            "Real-time dashboards",
            "Drift detection",
            "A/B testing",
            "Compliance reports"
        ],
        "ğŸ¢ Enterprise Integration": [
            "SIEM integration",
            "Ticketing systems",
            "Slack/Teams alerts",
            "Kubernetes deployment"
        ]
    }
    
    cols = st.columns(2)
    for idx, (title, features) in enumerate(extensions.items()):
        with cols[idx % 2]:
            st.markdown(f"### {title}")
            for feature in features:
                st.markdown(f"- {feature}")
            st.divider()
    
    # Job alignment
    st.markdown("### ğŸ“ Siemens Role Alignment")
    
    alignment = {
        "Evaluate AI Frameworks": "âœ… Comparison methodology, abstraction layer",
        "Build PoC AI Agents": "âœ… Working threat detection agent",
        "Monitor Output Quality": "âœ… Metrics dashboard, evaluation workflow",
        "AI + Security Education": "âœ… Domain-specific implementation",
        "Team Collaboration": "âœ… Clean code, docs, extensibility"
    }
    
    for req, demo in alignment.items():
        col1, col2 = st.columns([1, 2])
        with col1:
            st.markdown(f"**{req}**")
        with col2:
            st.markdown(demo)

def main():
    """Main app."""
    
    # Sidebar
    with st.sidebar:
        st.title("ğŸ›¡ï¸ AI Threat Agent")
        st.caption("PoC for Siemens Interview")
        
        st.divider()
        
        # Status
        if is_mock_mode():
            st.success("ğŸ­ Mock Mode Active")
            st.caption("Deterministic responses")
        else:
            st.info("ğŸŒ API Mode Active")
            st.caption("Calling Hugging Face")
        
        st.divider()
        
        # Quick guide
        st.markdown("""
        **Quick Guide:**
        1. ğŸ“– Overview
        2. ğŸš€ Try Live Demo
        3. ğŸ“ˆ Check Quality
        4. ğŸ”§ See Comparison
        5. ğŸ”® Future Ideas
        """)
        
        st.divider()
        st.caption("Built with Streamlit")
        st.caption("Lightweight & Fast")
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“– Overview",
        "ğŸš€ Live Demo",
        "ğŸ“ˆ Quality",
        "ğŸ”§ Frameworks",
        "ğŸ”® Future"
    ])
    
    with tab1:
        render_overview_tab()
    
    with tab2:
        render_demo_tab()
    
    with tab3:
        render_quality_tab()
    
    with tab4:
        render_framework_tab()
    
    with tab5:
        render_future_tab()

if __name__ == "__main__":
    main()
